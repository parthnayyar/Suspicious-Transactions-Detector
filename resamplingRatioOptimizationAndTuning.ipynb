{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875428e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import csv\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b24e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df = pd.read_csv('historical_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70074648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesses X_train\n",
    "def preprocess_X_train(X_train):\n",
    "    # convert x5 to float\n",
    "    X_train['x5'] = X_train['x5'].str.replace('%', '').astype(float)\n",
    "    \n",
    "    # convert x57 to numeric\n",
    "    X_train['x57'] = X_train['x57'].str.replace('$', '').astype(float)\n",
    "    \n",
    "    # use mode for categorical features and mean for non-categorical features to fill null values\n",
    "    # store means and modes for all columns to use in test data\n",
    "    means = {}\n",
    "    modes = {}\n",
    "    obj_columns = X_train.select_dtypes(include='object').columns\n",
    "    for column in X_train.columns:\n",
    "        if column in obj_columns:\n",
    "            mode = X_train[column].mode()[0]\n",
    "            X_train[column].fillna(mode, inplace=True)\n",
    "            modes[column] = mode\n",
    "        else:\n",
    "            mean = X_train[column].mean()\n",
    "            X_train[column].fillna(mean, inplace=True)\n",
    "            means[column] = mean\n",
    "        \n",
    "    # convert x49 to binary\n",
    "    X_train['x49'] = X_train['x49'].astype(bool).astype(int)\n",
    "    \n",
    "    # one-hot encode all categorical features\n",
    "    obj_columns = X_train.select_dtypes(include='object').columns\n",
    "    X_train = pd.get_dummies(data=X_train, columns=obj_columns)\n",
    "    \n",
    "    # normalize all features using min-max scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_normalized = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    \n",
    "    return X_train_normalized, means, modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5e441b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesses X_test\n",
    "def preprocess_X_test(X_test, means, modes):\n",
    "    # convert x5 to float\n",
    "    X_test['x5'] = X_test['x5'].str.replace('%', '').astype(float)\n",
    "    \n",
    "    # convert x57 to numeric\n",
    "    X_test['x57'] = X_test['x57'].str.replace('$', '').astype(float)\n",
    "    \n",
    "    # use means and modes from train data to fill null values\n",
    "    obj_columns = X_test.select_dtypes(include='object').columns\n",
    "    for column in X_test.columns:\n",
    "        if column in obj_columns:\n",
    "            X_test[column].fillna(modes[column], inplace=True)\n",
    "        else:\n",
    "            X_test[column].fillna(means[column], inplace=True)\n",
    "        \n",
    "    # convert x49 to binary\n",
    "    X_test['x49'] = X_test['x49'].astype(bool).astype(int)\n",
    "    \n",
    "    # one-hot encode all categorical features\n",
    "    obj_columns = X_test.select_dtypes(include='object').columns\n",
    "    X_test = pd.get_dummies(data=X_test, columns=obj_columns)\n",
    "    \n",
    "    # normalize all features using min-max scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_test_normalized = pd.DataFrame(scaler.fit_transform(X_test), columns=X_test.columns)\n",
    "    \n",
    "    return X_test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3884be51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits dataset into test and train and resamples train dataset\n",
    "def split_preprocess_undersample_oversample_data(df, resample, undersample_ratio, oversample_ratio):\n",
    "    X = df[df.columns[:-1]]\n",
    "    y = df['y']\n",
    "    \n",
    "    # splitting data into train and test datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2)\n",
    "    \n",
    "    if resample:\n",
    "        # preprocess X_train and X_test\n",
    "        X_train_preprocessed, means, modes = preprocess_X_train(X_train)\n",
    "        X_test_preprocessed = preprocess_X_test(X_test, means, modes)\n",
    "\n",
    "        # add a column of 0s if a column is present in X_train but missing in X_test\n",
    "        for column in X_train_preprocessed.columns:\n",
    "            if column not in X_test_preprocessed.columns:\n",
    "                X_test_preprocessed[column] = (np.zeros(len(X_test_preprocessed), )).astype(int)\n",
    "\n",
    "        # add a column of 0s if a column is present in X_test but missing in X_train\n",
    "        for column in X_test_preprocessed.columns:\n",
    "            if column not in X_train_preprocessed.columns:\n",
    "                X_train_preprocessed[column] = (np.zeros(len(X_train_preprocessed), )).astype(int)\n",
    "\n",
    "        # make sure that features are in same order in X_train and X_test\n",
    "        columns = X_train_preprocessed.columns.tolist()\n",
    "        columns = sorted(columns)\n",
    "        X_train_preprocessed = X_train_preprocessed[columns]\n",
    "        X_test_preprocessed = X_test_preprocessed[columns]\n",
    "        \n",
    "        # implement undersampling on X_train\n",
    "        random_undersample = RandomUnderSampler(sampling_strategy=undersample_ratio, random_state=0)\n",
    "        X_train_preprocessed_undersampled, y_train_undersampled = random_undersample.fit_resample(X_train_preprocessed, y_train)\n",
    "\n",
    "        # implement oversampling on X_train_undersampled_preprocessed\n",
    "        adasyn_oversample = ADASYN(sampling_strategy=oversample_ratio, random_state=0)\n",
    "        X_train_preprocessed_undersampled_oversampled, y_train_undersampled_oversampled = adasyn_oversample.fit_resample(X_train_preprocessed_undersampled, y_train_undersampled)\n",
    "        \n",
    "        return X_train_preprocessed_undersampled_oversampled, y_train_undersampled_oversampled, X_test_preprocessed, y_test\n",
    "    \n",
    "    else:\n",
    "        # preprocess X_train and X_test\n",
    "        X_train_preprocessed, means, modes = preprocess_X_train(X_train)\n",
    "        X_test_preprocessed = preprocess_X_test(X_test, means, modes)\n",
    "\n",
    "        # add a column of 0s if a column is present in X_train but missing in X_test\n",
    "        for column in X_train_preprocessed.columns:\n",
    "            if column not in X_test_preprocessed.columns:\n",
    "                X_test_preprocessed[column] = (np.zeros(len(X_test_preprocessed), )).astype(int)\n",
    "\n",
    "        # add a column of 0s if a column is present in X_test but missing in X_train\n",
    "        for column in X_test_preprocessed.columns:\n",
    "            if column not in X_train_preprocessed.columns:\n",
    "                X_train_preprocessed[column] = (np.zeros(len(X_train_preprocessed), )).astype(int)\n",
    "\n",
    "        # make sure that features are in same order in X_train and X_test\n",
    "        columns = X_train_preprocessed.columns.tolist()\n",
    "        columns = sorted(columns)\n",
    "        X_train_preprocessed = X_train_preprocessed[columns]\n",
    "        X_test_preprocessed = X_test_preprocessed[columns]\n",
    "        \n",
    "        return X_train_preprocessed, y_train, X_test_preprocessed, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec36eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vairables to track highest recall score of minority class, best resampling ratio, and best model\n",
    "highest_suspicious_recall = 0\n",
    "best_resampling_ratio = None\n",
    "resampled = False\n",
    "best_model = None\n",
    "best_X_train = None\n",
    "best_y_train = None\n",
    "\n",
    "# define accuracy threshold\n",
    "accuracy_threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1242712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models\n",
    "svm = {'name' : 'svm', 'model' : SVC()}\n",
    "rf = {'name' : 'random forest', 'model' : RandomForestClassifier()}\n",
    "lr = {'name' : 'logistic regression', 'model' : LogisticRegression()}\n",
    "knn = [{'name' : 'knn, k='+str(i+1), 'model' : KNeighborsClassifier(n_neighbors=i+1)} for i in range(5)]\n",
    "model_dicts = [svm, rf, lr] + knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4780f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no resampling\n",
    "for model_dict in model_dicts:\n",
    "    model = model_dict['model']\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = split_preprocess_undersample_oversample_data(df, False, 0, 0)\n",
    "    model.fit(X_train, y_train)\n",
    "    if model_dict['name'][:3] == 'knn':\n",
    "        y_pred = model.predict(X_test.values)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "    # track recall and accuracy\n",
    "    recall = precision_recall_fscore_support(y_test, y_pred)[1][1]\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # retain a model if it is better than current best model\n",
    "    if accuracy >= accuracy_threshold and recall > highest_suspicious_recall:\n",
    "        highest_suspicious_recall = recall\n",
    "        best_model = model_dict\n",
    "        best_X_train = X_train\n",
    "        best_y_train = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0df18bcb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undersample_ratio: (10, 90)\n",
      "oversample_ratio: (25, 75)\n",
      "\n",
      "undersample_ratio: (10, 90)\n",
      "oversample_ratio: (30, 70)\n",
      "\n",
      "undersample_ratio: (10, 90)\n",
      "oversample_ratio: (35, 65)\n",
      "\n",
      "undersample_ratio: (10, 90)\n",
      "oversample_ratio: (40, 60)\n",
      "\n",
      "undersample_ratio: (10, 90)\n",
      "oversample_ratio: (45, 55)\n",
      "\n",
      "undersample_ratio: (10, 90)\n",
      "oversample_ratio: (50, 50)\n",
      "\n",
      "undersample_ratio: (15, 85)\n",
      "oversample_ratio: (25, 75)\n",
      "\n",
      "undersample_ratio: (15, 85)\n",
      "oversample_ratio: (30, 70)\n",
      "\n",
      "undersample_ratio: (15, 85)\n",
      "oversample_ratio: (35, 65)\n",
      "\n",
      "undersample_ratio: (15, 85)\n",
      "oversample_ratio: (40, 60)\n",
      "\n",
      "undersample_ratio: (15, 85)\n",
      "oversample_ratio: (45, 55)\n",
      "\n",
      "undersample_ratio: (15, 85)\n",
      "oversample_ratio: (50, 50)\n",
      "\n",
      "undersample_ratio: (20, 80)\n",
      "oversample_ratio: (25, 75)\n",
      "skipped\n",
      "\n",
      "undersample_ratio: (20, 80)\n",
      "oversample_ratio: (30, 70)\n",
      "\n",
      "undersample_ratio: (20, 80)\n",
      "oversample_ratio: (35, 65)\n",
      "\n",
      "undersample_ratio: (20, 80)\n",
      "oversample_ratio: (40, 60)\n",
      "\n",
      "undersample_ratio: (20, 80)\n",
      "oversample_ratio: (45, 55)\n",
      "\n",
      "undersample_ratio: (20, 80)\n",
      "oversample_ratio: (50, 50)\n",
      "\n",
      "undersample_ratio: (25, 75)\n",
      "oversample_ratio: (30, 70)\n",
      "skipped\n",
      "\n",
      "undersample_ratio: (25, 75)\n",
      "oversample_ratio: (35, 65)\n",
      "\n",
      "undersample_ratio: (25, 75)\n",
      "oversample_ratio: (40, 60)\n",
      "\n",
      "undersample_ratio: (25, 75)\n",
      "oversample_ratio: (45, 55)\n",
      "\n",
      "undersample_ratio: (25, 75)\n",
      "oversample_ratio: (50, 50)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# different resampling ratios\n",
    "for usr in [(10, 90), (15, 85), (20, 80), (25, 75)]:\n",
    "    for osr in [(25, 75), (30, 70), (35, 65), (40, 60), (45, 55), (50, 50)]:\n",
    "        if usr[0] < osr[0]:\n",
    "            print('undersample_ratio:', usr)\n",
    "            print('oversample_ratio:', osr)\n",
    "            \n",
    "            try:\n",
    "                for model_dict in model_dicts:\n",
    "                    model = model_dict['model']\n",
    "                    \n",
    "                    X_train, y_train, X_test, y_test = split_preprocess_undersample_oversample_data(df, True, usr[0]/usr[1], osr[0]/osr[1])\n",
    "                    model.fit(X_train, y_train)\n",
    "                    if model_dict['name'][:3] == 'knn':\n",
    "                        y_pred = model.predict(X_test.values)\n",
    "                    else:\n",
    "                        y_pred = model.predict(X_test)\n",
    "                        \n",
    "                    # track recall and accuracy\n",
    "                    recall = precision_recall_fscore_support(y_test, y_pred)[1][1]\n",
    "                    accuracy = accuracy_score(y_test, y_pred)\n",
    "                    \n",
    "                    # retain a model if it is better than current best model\n",
    "                    if accuracy >= accuracy_threshold and recall > highest_suspicious_recall:\n",
    "                        highest_suspicious_recall = recall\n",
    "                        best_resampling_ratio = (usr, osr)\n",
    "                        best_model = model_dict\n",
    "                        best_X_train = X_train    \n",
    "                        best_y_train = y_train\n",
    "                        if not resampled:\n",
    "                            resampled = True\n",
    "                print()\n",
    "                        \n",
    "            except:\n",
    "                print('skipped')\n",
    "                print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5a35ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best resampling ratio: ((25, 75), (40, 60))\n",
      "best model: random forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1512\n",
      "           1       0.61      0.90      0.72        88\n",
      "\n",
      "    accuracy                           0.96      1600\n",
      "   macro avg       0.80      0.93      0.85      1600\n",
      "weighted avg       0.97      0.96      0.97      1600\n",
      "\n",
      "Log loss: 1.3516370020918933\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if resampled:\n",
    "    print('best resampling ratio:', best_resampling_ratio)\n",
    "else:\n",
    "    print('no resampling')\n",
    "\n",
    "print('best model:', best_model['name'])\n",
    "\n",
    "if best_model['name'][:3] == 'knn':\n",
    "    y_pred = best_model['model'].predict(X_test.values)\n",
    "else:\n",
    "    y_pred = best_model['model'].predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Log loss:', log_loss(y_test, y_pred))\n",
    "\n",
    "# display confusion matrix\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(y_test, y_pred), display_labels=[\"Not Suspicious\", \"Suspicious\"])\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff6e8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess current transactions data\n",
    "current = pd.read_csv('current_transaction.csv')\n",
    "\n",
    "# convert x5 to numeric\n",
    "current['x5'] = current['x5'].str.replace('%', '').astype(float)\n",
    "\n",
    "# convert x57 to numeric\n",
    "current['x57'] = current['x57'].str.replace('$', '').astype(float)\n",
    "\n",
    "# convert x5 and x7 to numeric in histoical dataframe\n",
    "df['x5'] = df['x5'].str.replace('%', '').astype(float)\n",
    "df['x57'] = df['x57'].str.replace('$', '').astype(float)\n",
    "\n",
    "# use means and modes from historical data to fill null values\n",
    "obj_columns = current.select_dtypes(include='object').columns\n",
    "for column in current.columns:\n",
    "    if column in obj_columns:\n",
    "        historical_mode = df[column].mode()[0]\n",
    "        current[column].fillna(historical_mode, inplace=True)\n",
    "    else:\n",
    "        historical_mean = df[column].mean()\n",
    "        current[column].fillna(historical_mean, inplace=True)\n",
    "\n",
    "# convert x49 to binary\n",
    "current['x49'] = current['x49'].astype(bool).astype(int)\n",
    "\n",
    "# one-hot encode all categorical features\n",
    "obj_columns = current.select_dtypes(include='object').columns\n",
    "current = pd.get_dummies(data=current, columns=obj_columns)\n",
    "\n",
    "# normalize all features using min-max scaling\n",
    "scaler = MinMaxScaler()\n",
    "current_normalized = pd.DataFrame(scaler.fit_transform(current), columns=current.columns)\n",
    "\n",
    "# add a column of 0s if a column is present in best_X_train but missing in current\n",
    "for column in best_X_train.columns:\n",
    "    if column not in current_normalized.columns:\n",
    "        current_normalized[column] = (np.zeros(len(current_normalized), )).astype(int)\n",
    "\n",
    "# add a column of 0s if a column is present in current but missing in best_X_train\n",
    "for column in current_normalized.columns:\n",
    "    if column not in best_X_train.columns:\n",
    "        best_X_train[column] = (np.zeros(len(best_X_train), )).astype(int)\n",
    "                \n",
    "# make sure that features are in same order in best_X_train and current\n",
    "columns = best_X_train.columns.tolist()\n",
    "columns = sorted(columns)\n",
    "best_X_train = best_X_train[columns]\n",
    "current_normalized = current_normalized[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5242176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit best_X_train to best model and make predictions for current transactions\n",
    "best_model['model'].fit(best_X_train, best_y_train)\n",
    "if best_model['name'][:3] == 'knn':\n",
    "    y_pred = best_model['model'].predict(current_normalized.values)\n",
    "else:\n",
    "    y_pred = best_model['model'].predict(current_normalized)\n",
    "\n",
    "# write predictions to predictions.csv\n",
    "y_pred = [[pred] for pred in y_pred]\n",
    "with open('predictions.csv', 'w', newline='') as out:\n",
    "    writer = csv.writer(out)\n",
    "    writer.writerow(['y'])\n",
    "    writer.writerows(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d70f3dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1870\n",
       "1     130\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pd.read_csv('predictions.csv')\n",
    "preds['y'].value_counts()\n",
    "# 93.5% seems about right"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
